{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes Classifaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import utilities as util\n",
    "import nlp as nlp\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score,train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix,classification_report\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nlp' from 'C:\\\\Users\\\\teddy\\\\Documents\\\\Research Project\\\\SreYantra_Data\\\\BugZ\\\\TKnegsampleGeneration\\\\nlp.py'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(util)\n",
    "importlib.reload(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_pairs = \"Teddy_Data/AllDependentPairs.csv\"\n",
    "I_pairs = \"Teddy_Data/AllIndependentPairs.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dp = pd.read_csv(D_pairs, low_memory = False)\n",
    "df_ip = pd.read_csv(I_pairs, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnamed_columns = [\"Unnamed: 0\", \"Unnamed: 0.1\"]\n",
    "df_dp = df_dp.drop(columns = unnamed_columns)\n",
    "df_ip = df_ip.drop(columns = unnamed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of independent pairs is 740230\n",
      "The amount of dependent pairs is 62011\n"
     ]
    }
   ],
   "source": [
    "print(\"The amount of independent pairs is {}\".format(len(df_ip)))\n",
    "print(\"The amount of dependent pairs is {}\".format(len(df_dp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model for future uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "count_vect = util.create_vectorizor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 for training, 500 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dp[df_dp[\"req1Product\"] == \"Firefox\"].sample(int(train_size/2))\n",
    "df = df.append(df_ip[df_ip[\"req1Product\"] == \"Firefox\"].sample(int(train_size/2)))\n",
    "# randomize the dataframe\n",
    "df = df.sample(frac = 1)\n",
    "# get the test series'\n",
    "binary_class = np.array(df[\"BinaryClass\"])\n",
    "multi_class = df[\"MultiClass\"]\n",
    "## drop unimportant columns from training\n",
    "train_df = df.drop(columns = ['BinaryClass', 'MultiClass',\"req1Product\",\"req2Product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = nlp.generate_ngrams_df(train_df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.fit_transform(np.array(train_df))\n",
    "X_train_tfidf= tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model (Binary Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = MultinomialNB().fit(X_train_tfidf,binary_class.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model (Binary Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.81\n",
      " f1score : 0.81\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.804\n",
      " f1score : 0.8\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.798\n",
      " f1score : 0.8\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.786\n",
      " f1score : 0.79\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.808\n",
      " f1score : 0.81\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.782\n",
      " f1score : 0.78\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.816\n",
      " f1score : 0.81\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.804\n",
      " f1score : 0.8\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.786\n",
      " f1score : 0.78\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Classifier Test Score : 0.8\n",
      " f1score : 0.8\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    test_df = df_dp[df_dp[\"req1Product\"] == \"Core\"].sample(int(test_size/2))\n",
    "    test_df = test_df.append(df_ip[df_ip[\"req1Product\"] == \"Core\"].sample(int(test_size/2)))\n",
    "    test_df = test_df.sample(frac = 1)\n",
    "    test_binary = np.array(test_df[\"BinaryClass\"])\n",
    "    test_df = test_df.drop(columns = ['BinaryClass', 'MultiClass',\"req1Product\",\"req2Product\"])\n",
    "    \n",
    "    test_df = nlp.generate_ngrams_df(test_df,2)\n",
    "    \n",
    "    X_test_counts = count_vect.transform(np.array(test_df))\n",
    "    X_test_tfidf= tfidf_transformer.fit_transform(X_test_counts)\n",
    "\n",
    "    predict_labels = clf_model.predict(X_test_tfidf)\n",
    "    actualLabels = np.array(test_binary).astype('int')\n",
    "\n",
    "    confusion_matrix(actualLabels, predict_labels)\n",
    "\n",
    "    clf_test_score = clf_model.score(X_test_tfidf,actualLabels)\n",
    "    print(\"\\n\"+100*\"-\")\n",
    "    print(\" Classifier Test Score : \"+str(clf_test_score))\n",
    "\n",
    "    precision = round(precision_score(actualLabels, predict_labels,average='macro'),2)\n",
    "    recall = round(recall_score(actualLabels, predict_labels,average='macro'),2)\n",
    "    f1 = round(f1_score(actualLabels, predict_labels,average='macro'),2)\n",
    "    print(\" f1score : \"+str(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose what is test and what is train (Multi Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = util.train_test_multi_class(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model (Multi Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf = util.create_classified_sets(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = MultinomialNB().fit(X_train_tfidf,np.array(train_y).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model (Multi Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = clf_model.predict(X_test_tfidf)\n",
    "actualLabels = np.array(test_y).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_test_score = clf_model.score(X_test_tfidf,actualLabels)\n",
    "print(\"\\n\"+100*\"-\")\n",
    "print(\" Classifier Test Score : \"+str(clf_test_score))\n",
    "\n",
    "\n",
    "f1 = round(f1_score(actualLabels, predict_labels,average='macro'),2)\n",
    "print(\" f1score : \"+str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force!!! (Binary Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize Verfication sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_projects = len(df[\"req1Product\"].value_counts()) - 1\n",
    "df_unique = df_dp[\"req1Product\"].unique()\n",
    "df_unique = np.intersect1d(df_unique, df_ip[\"req1Product\"].unique())\n",
    "df_scores = pd.DataFrame(columns = [\"Train Project\", \"Test Project\", \"Prediction Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### important global variables for model to use\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "count_vect = util.create_vectorizor()\n",
    "ngrams = 2\n",
    "important_projects = [\"Core\", \"Firefox\", \"Thunderbird\" ,\"Bugzilla\", \"SeaMonkey\"]\n",
    "clf = MultinomialNB()\n",
    "skf = StratifiedKFold(10)\n",
    "new_results = pd.DataFrame(columns = [\"Train Project\", \"Train Size\", \"Test Project\", \"Test Size\", \"Average Validation Score (15*15 fold)\",\"Average f1 score (10 Tests)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Project 1: Core\n",
      "Training Project 2: Core\n",
      "Training Project 3: Core\n",
      "Training Project 4: Core\n",
      "Training Project 5: Core\n",
      "Training Project 6: Firefox\n",
      "Training Project 7: Firefox\n",
      "Training Project 8: Firefox\n",
      "Training Project 9: Firefox\n",
      "Training Project 10: Firefox\n",
      "Training Project 11: Thunderbird\n",
      "Training Project 12: Thunderbird\n",
      "Training Project 13: Thunderbird\n",
      "Training Project 14: Thunderbird\n",
      "Training Project 15: Thunderbird\n",
      "Training Project 16: Bugzilla\n",
      "Training Project 17: Bugzilla\n",
      "Training Project 18: Bugzilla\n",
      "Training Project 19: Bugzilla\n",
      "Training Project 20: Bugzilla\n",
      "Training Project 21: SeaMonkey\n",
      "Training Project 22: SeaMonkey\n",
      "Training Project 23: SeaMonkey\n",
      "Training Project 24: SeaMonkey\n",
      "Training Project 25: SeaMonkey\n"
     ]
    }
   ],
   "source": [
    "project_num = 0\n",
    "for df_name in important_projects:\n",
    "    for i in range (5):\n",
    "        if (i == 0):\n",
    "            train_size = 100\n",
    "            test_size = train_size/2\n",
    "        else:\n",
    "            train_size = train_size * 2\n",
    "            test_size = train_size/2\n",
    "        ### Training and Verfication Phase ####\n",
    "        project_num = project_num + 1\n",
    "        print(\"Training Project {}: {}\".format(project_num, df_name))\n",
    "        ## get the pairs from both dataset with the same req1product\n",
    "        d_pairs = df_dp[df_dp[\"req1Product\"] == df_name]\n",
    "        i_pairs = df_ip[df_ip[\"req1Product\"] == df_name]\n",
    "        train_df = d_pairs.sample(int(train_size/2))\n",
    "        train_df = train_df.append(i_pairs.sample(int(train_size/2)))\n",
    "        ### randomize the data frame\n",
    "        train_df = train_df.sample(frac = 1)\n",
    "        train_binary_class = np.array(train_df[\"BinaryClass\"])\n",
    "        train_df = train_df.drop(columns = ['BinaryClass', 'MultiClass',\"req1Product\",\"req2Product\"])\n",
    "        train_df = nlp.generate_ngrams_df(train_df,ngrams)\n",
    "        ## condense the data\n",
    "        X_train_counts = count_vect.fit_transform(np.array(train_df))\n",
    "        X_train_tfidf= tfidf_transformer.fit_transform(X_train_counts)\n",
    "        ## k-fold validation\n",
    "        scores = cross_val_score(clf, X_train_tfidf, train_binary_class, cv = skf)\n",
    "        avgValidation = np.average(scores)\n",
    "        ## checking for a high enough validation score\n",
    "        if (avgValidation < 0.9):\n",
    "            continue\n",
    "        clf_model = MultinomialNB().fit(X_train_tfidf,train_binary_class.astype('int'))\n",
    "        for df_name2 in important_projects:\n",
    "            if df_name == df_name2:\n",
    "                continue\n",
    "            d_pairs2 = df_dp[df_dp[\"req1Product\"] == df_name2]\n",
    "            i_pairs2 = df_ip[df_ip[\"req1Product\"] == df_name2]\n",
    "            ## we want to run this 10 times and take 10 different random samples\n",
    "            f1_scores = []\n",
    "            for y in range(10):\n",
    "                test_df = d_pairs2.sample(int(test_size/2))\n",
    "                test_df = test_df.append(i_pairs2.sample(int(test_size/2)))\n",
    "                test_df = test_df.sample(frac = 1)\n",
    "                test_binary = np.array(test_df[\"BinaryClass\"])\n",
    "                test_df = test_df.drop(columns = ['BinaryClass', 'MultiClass',\"req1Product\",\"req2Product\"])\n",
    "                test_df = nlp.generate_ngrams_df(test_df,ngrams)\n",
    "                ## condense the data \n",
    "                X_test_counts = count_vect.transform(np.array(test_df))\n",
    "                X_test_tfidf= tfidf_transformer.fit_transform(X_test_counts)\n",
    "                ## seperate prediction array from actual value array\n",
    "                predict_labels = clf_model.predict(X_test_tfidf)\n",
    "                actualLabels = np.array(test_binary).astype('int')\n",
    "                ## create the confusion matrix\n",
    "                cm = confusion_matrix(actualLabels, predict_labels)\n",
    "                precision = round(precision_score(actualLabels, predict_labels,average='macro'),2)\n",
    "                recall = round(recall_score(actualLabels, predict_labels,average='macro'),2)\n",
    "                f1 = round(f1_score(actualLabels, predict_labels,average='macro'),2)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "            avgf1score = np.average(f1_scores)\n",
    "            result = {\"Train Project\" : df_name,\n",
    "                      \"Train Size\" : train_size,\n",
    "                      \"Test Project\": df_name2,\n",
    "                      \"Test Size\": test_size,\n",
    "                      \"Average Validation Score (10*10 fold)\" : avgValidation,\n",
    "                      \"Average f1 score (10 Tests)\" : avgf1score}\n",
    "            new_results = new_results.append(result, ignore_index = True)\n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Project</th>\n",
       "      <th>Train Size</th>\n",
       "      <th>Test Project</th>\n",
       "      <th>Test Size</th>\n",
       "      <th>Average Validation Score (15*15 fold)</th>\n",
       "      <th>Average f1 score (10 Tests)</th>\n",
       "      <th>Average Validation Score (10*10 fold)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core</td>\n",
       "      <td>400</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.91750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core</td>\n",
       "      <td>400</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.91750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core</td>\n",
       "      <td>400</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.91750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core</td>\n",
       "      <td>400</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.91750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core</td>\n",
       "      <td>800</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Core</td>\n",
       "      <td>800</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Core</td>\n",
       "      <td>800</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Core</td>\n",
       "      <td>800</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Core</td>\n",
       "      <td>1600</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.95750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Core</td>\n",
       "      <td>1600</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.95750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Core</td>\n",
       "      <td>1600</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.95750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Core</td>\n",
       "      <td>1600</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.95750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>100</td>\n",
       "      <td>Core</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>100</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>100</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>100</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>200</td>\n",
       "      <td>Core</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>200</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>200</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>200</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>400</td>\n",
       "      <td>Core</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>400</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>400</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>400</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.94750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>800</td>\n",
       "      <td>Core</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>800</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>800</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>800</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.96375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>1600</td>\n",
       "      <td>Core</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.97250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Firefox</td>\n",
       "      <td>1600</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.97250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800</td>\n",
       "      <td>Core</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.93125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.93125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.93125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.93125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>1600</td>\n",
       "      <td>Core</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>1600</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>1600</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>1600</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400</td>\n",
       "      <td>Core</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.92500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800</td>\n",
       "      <td>Core</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>1600</td>\n",
       "      <td>Core</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>1600</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>1600</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>1600</td>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800</td>\n",
       "      <td>Core</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>800</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>1600</td>\n",
       "      <td>Core</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.95125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>1600</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.95125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>1600</td>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.95125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SeaMonkey</td>\n",
       "      <td>1600</td>\n",
       "      <td>Bugzilla</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.95125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Project Train Size Test Project  Test Size  \\\n",
       "0           Core        400      Firefox      200.0   \n",
       "1           Core        400  Thunderbird      200.0   \n",
       "2           Core        400     Bugzilla      200.0   \n",
       "3           Core        400    SeaMonkey      200.0   \n",
       "4           Core        800      Firefox      400.0   \n",
       "5           Core        800  Thunderbird      400.0   \n",
       "6           Core        800     Bugzilla      400.0   \n",
       "7           Core        800    SeaMonkey      400.0   \n",
       "8           Core       1600      Firefox      800.0   \n",
       "9           Core       1600  Thunderbird      800.0   \n",
       "10          Core       1600     Bugzilla      800.0   \n",
       "11          Core       1600    SeaMonkey      800.0   \n",
       "12       Firefox        100         Core       50.0   \n",
       "13       Firefox        100  Thunderbird       50.0   \n",
       "14       Firefox        100     Bugzilla       50.0   \n",
       "15       Firefox        100    SeaMonkey       50.0   \n",
       "16       Firefox        200         Core      100.0   \n",
       "17       Firefox        200  Thunderbird      100.0   \n",
       "18       Firefox        200     Bugzilla      100.0   \n",
       "19       Firefox        200    SeaMonkey      100.0   \n",
       "20       Firefox        400         Core      200.0   \n",
       "21       Firefox        400  Thunderbird      200.0   \n",
       "22       Firefox        400     Bugzilla      200.0   \n",
       "23       Firefox        400    SeaMonkey      200.0   \n",
       "24       Firefox        800         Core      400.0   \n",
       "25       Firefox        800  Thunderbird      400.0   \n",
       "26       Firefox        800     Bugzilla      400.0   \n",
       "27       Firefox        800    SeaMonkey      400.0   \n",
       "28       Firefox       1600         Core      800.0   \n",
       "29       Firefox       1600  Thunderbird      800.0   \n",
       "..           ...        ...          ...        ...   \n",
       "34   Thunderbird        400     Bugzilla      200.0   \n",
       "35   Thunderbird        400    SeaMonkey      200.0   \n",
       "36   Thunderbird        800         Core      400.0   \n",
       "37   Thunderbird        800      Firefox      400.0   \n",
       "38   Thunderbird        800     Bugzilla      400.0   \n",
       "39   Thunderbird        800    SeaMonkey      400.0   \n",
       "40   Thunderbird       1600         Core      800.0   \n",
       "41   Thunderbird       1600      Firefox      800.0   \n",
       "42   Thunderbird       1600     Bugzilla      800.0   \n",
       "43   Thunderbird       1600    SeaMonkey      800.0   \n",
       "44      Bugzilla        400         Core      200.0   \n",
       "45      Bugzilla        400      Firefox      200.0   \n",
       "46      Bugzilla        400  Thunderbird      200.0   \n",
       "47      Bugzilla        400    SeaMonkey      200.0   \n",
       "48      Bugzilla        800         Core      400.0   \n",
       "49      Bugzilla        800      Firefox      400.0   \n",
       "50      Bugzilla        800  Thunderbird      400.0   \n",
       "51      Bugzilla        800    SeaMonkey      400.0   \n",
       "52      Bugzilla       1600         Core      800.0   \n",
       "53      Bugzilla       1600      Firefox      800.0   \n",
       "54      Bugzilla       1600  Thunderbird      800.0   \n",
       "55      Bugzilla       1600    SeaMonkey      800.0   \n",
       "56     SeaMonkey        800         Core      400.0   \n",
       "57     SeaMonkey        800      Firefox      400.0   \n",
       "58     SeaMonkey        800  Thunderbird      400.0   \n",
       "59     SeaMonkey        800     Bugzilla      400.0   \n",
       "60     SeaMonkey       1600         Core      800.0   \n",
       "61     SeaMonkey       1600      Firefox      800.0   \n",
       "62     SeaMonkey       1600  Thunderbird      800.0   \n",
       "63     SeaMonkey       1600     Bugzilla      800.0   \n",
       "\n",
       "    Average Validation Score (15*15 fold)  Average f1 score (10 Tests)  \\\n",
       "0                                     NaN                        0.720   \n",
       "1                                     NaN                        0.613   \n",
       "2                                     NaN                        0.527   \n",
       "3                                     NaN                        0.595   \n",
       "4                                     NaN                        0.737   \n",
       "5                                     NaN                        0.649   \n",
       "6                                     NaN                        0.523   \n",
       "7                                     NaN                        0.624   \n",
       "8                                     NaN                        0.756   \n",
       "9                                     NaN                        0.642   \n",
       "10                                    NaN                        0.538   \n",
       "11                                    NaN                        0.645   \n",
       "12                                    NaN                        0.751   \n",
       "13                                    NaN                        0.663   \n",
       "14                                    NaN                        0.528   \n",
       "15                                    NaN                        0.663   \n",
       "16                                    NaN                        0.828   \n",
       "17                                    NaN                        0.656   \n",
       "18                                    NaN                        0.497   \n",
       "19                                    NaN                        0.640   \n",
       "20                                    NaN                        0.780   \n",
       "21                                    NaN                        0.696   \n",
       "22                                    NaN                        0.497   \n",
       "23                                    NaN                        0.685   \n",
       "24                                    NaN                        0.793   \n",
       "25                                    NaN                        0.680   \n",
       "26                                    NaN                        0.510   \n",
       "27                                    NaN                        0.685   \n",
       "28                                    NaN                        0.801   \n",
       "29                                    NaN                        0.688   \n",
       "..                                    ...                          ...   \n",
       "34                                    NaN                        0.590   \n",
       "35                                    NaN                        0.675   \n",
       "36                                    NaN                        0.672   \n",
       "37                                    NaN                        0.720   \n",
       "38                                    NaN                        0.569   \n",
       "39                                    NaN                        0.715   \n",
       "40                                    NaN                        0.664   \n",
       "41                                    NaN                        0.692   \n",
       "42                                    NaN                        0.561   \n",
       "43                                    NaN                        0.718   \n",
       "44                                    NaN                        0.635   \n",
       "45                                    NaN                        0.606   \n",
       "46                                    NaN                        0.644   \n",
       "47                                    NaN                        0.640   \n",
       "48                                    NaN                        0.637   \n",
       "49                                    NaN                        0.627   \n",
       "50                                    NaN                        0.679   \n",
       "51                                    NaN                        0.641   \n",
       "52                                    NaN                        0.622   \n",
       "53                                    NaN                        0.611   \n",
       "54                                    NaN                        0.608   \n",
       "55                                    NaN                        0.592   \n",
       "56                                    NaN                        0.675   \n",
       "57                                    NaN                        0.729   \n",
       "58                                    NaN                        0.788   \n",
       "59                                    NaN                        0.524   \n",
       "60                                    NaN                        0.700   \n",
       "61                                    NaN                        0.720   \n",
       "62                                    NaN                        0.782   \n",
       "63                                    NaN                        0.537   \n",
       "\n",
       "    Average Validation Score (10*10 fold)  \n",
       "0                                 0.91750  \n",
       "1                                 0.91750  \n",
       "2                                 0.91750  \n",
       "3                                 0.91750  \n",
       "4                                 0.95375  \n",
       "5                                 0.95375  \n",
       "6                                 0.95375  \n",
       "7                                 0.95375  \n",
       "8                                 0.95750  \n",
       "9                                 0.95750  \n",
       "10                                0.95750  \n",
       "11                                0.95750  \n",
       "12                                0.95000  \n",
       "13                                0.95000  \n",
       "14                                0.95000  \n",
       "15                                0.95000  \n",
       "16                                0.92500  \n",
       "17                                0.92500  \n",
       "18                                0.92500  \n",
       "19                                0.92500  \n",
       "20                                0.94750  \n",
       "21                                0.94750  \n",
       "22                                0.94750  \n",
       "23                                0.94750  \n",
       "24                                0.96375  \n",
       "25                                0.96375  \n",
       "26                                0.96375  \n",
       "27                                0.96375  \n",
       "28                                0.97250  \n",
       "29                                0.97250  \n",
       "..                                    ...  \n",
       "34                                0.93000  \n",
       "35                                0.93000  \n",
       "36                                0.93125  \n",
       "37                                0.93125  \n",
       "38                                0.93125  \n",
       "39                                0.93125  \n",
       "40                                0.92500  \n",
       "41                                0.92500  \n",
       "42                                0.92500  \n",
       "43                                0.92500  \n",
       "44                                0.92500  \n",
       "45                                0.92500  \n",
       "46                                0.92500  \n",
       "47                                0.92500  \n",
       "48                                0.95375  \n",
       "49                                0.95375  \n",
       "50                                0.95375  \n",
       "51                                0.95375  \n",
       "52                                0.96875  \n",
       "53                                0.96875  \n",
       "54                                0.96875  \n",
       "55                                0.96875  \n",
       "56                                0.92375  \n",
       "57                                0.92375  \n",
       "58                                0.92375  \n",
       "59                                0.92375  \n",
       "60                                0.95125  \n",
       "61                                0.95125  \n",
       "62                                0.95125  \n",
       "63                                0.95125  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.to_csv(\"New_Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_num = 0\n",
    "## every project will be used as a training model\n",
    "for df_name in df_unique:\n",
    "    project_num = project_num + 1\n",
    "    train = df[df[\"req1Product\"] == df_name]\n",
    "    independent = len(train[train[\"BinaryClass\"] == 0])\n",
    "    dependent = len(train[train[\"BinaryClass\"] == 1])\n",
    "    ## if a data set only has less than 5 pairs of each, don't even bother training\n",
    "    if ((independent < 5) or (dependent < 5)):\n",
    "        print(\"Not using {}\".format(df_name))\n",
    "        continue\n",
    "    ## if a data set's independent pairs are greater than dependent pairs, balance to match dependent pair count\n",
    "    else:\n",
    "        train = util.balance_train(train)\n",
    "    train_x, train_y = util.x_y_split(train)\n",
    "    ## classify and condense the model\n",
    "    X_train_counts = count_vect.fit_transform(np.array(train_x))\n",
    "    X_train_tfidf= tfidf_transformer.fit_transform(X_train_counts)\n",
    "    ## train and fit the model\n",
    "    clf_model = MultinomialNB().fit(X_train_tfidf,np.array(train_y).astype('int'))\n",
    "    ## prompt the user which model is currently being used to test results\n",
    "    print(\"Currently Testing using {} model, this is project number {} out of {}\".format(df_name, project_num, len(df_unique)))\n",
    "    # every training model will test all other models\n",
    "    for df_name2 in df_unique:\n",
    "        if df_name != df_name2:\n",
    "            test = df[df[\"req1Product\"] == df_name2]\n",
    "            test_x, test_y = util.x_y_split(test)\n",
    "            X_test_counts = count_vect.transform(np.array(test_x))\n",
    "            X_test_tfidf= tfidf_transformer.fit_transform(X_test_counts)\n",
    "            predict_labels = clf_model.predict(X_test_tfidf)\n",
    "            actualLabels = np.array(test_y).astype('int')\n",
    "            ## will use f1 scores to see how well the modelsdo\n",
    "            clf_test_score = clf_model.score(X_test_tfidf,actualLabels)\n",
    "            ## add results to the dataframe\n",
    "            result = {\"Train Project\": df_name, \"Test Project\": df_name2, \"Prediction Score\": \"{:.2f}\".format(clf_test_score)}\n",
    "            df_scores = df_scores.append(result, ignore_index = True)\n",
    "\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(\"PredictionScores_BinaryClass.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force!!! (MultiClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(columns = [\"Train Project\", \"Test Project\", \"Prediction Score\"])\n",
    "project_num = 0\n",
    "## every project will be used as a training model\n",
    "for df_name in df_unique:\n",
    "    project_num = project_num + 1\n",
    "    train = df[df[\"req1Product\"] == df_name]\n",
    "    independent = len(df[(df[\"req1Product\"] == df_name) & (df[\"BinaryClass\"] == 0)])\n",
    "    dependent = len(df[(df[\"req1Product\"] == df_name) & (df[\"BinaryClass\"] == 1)])\n",
    "    ## if a data set only has less than 5 pairs of each, don't even bother training\n",
    "    if ((independent < 5) or (dependent < 5)):\n",
    "        print(\"Not using {}\".format(df_name))\n",
    "        continue\n",
    "    ## if a data set's independent pairs are greater than dependent pairs, balance to match dependent pair count\n",
    "    else:\n",
    "        train = util.balance_train(train)\n",
    "    train_x, train_y = util.x_y_multiclass_split(train)\n",
    "    ## classify and condense the model\n",
    "    X_train_counts = count_vect.fit_transform(np.array(train_x))\n",
    "    X_train_tfidf= tfidf_transformer.fit_transform(X_train_counts)\n",
    "    ## train and fit the model\n",
    "    clf_model = MultinomialNB().fit(X_train_tfidf,np.array(train_y).astype('int'))\n",
    "    ## prompt the user which model is currently being used to test results\n",
    "    print(\"Currently Testing using {} model, this is project number {}\".format(df_name, project_num))\n",
    "    # every training model will test all other models\n",
    "    for df_name2 in df_unique:\n",
    "        if df_name != df_name2:\n",
    "            test = df[df[\"req1Product\"] == df_name2]\n",
    "            test_x, test_y = util.x_y_multiclass_split(test)\n",
    "            X_test_counts = count_vect.transform(np.array(test_x))\n",
    "            X_test_tfidf= tfidf_transformer.fit_transform(X_test_counts)\n",
    "            predict_labels = clf_model.predict(X_test_tfidf)\n",
    "            actualLabels = np.array(test_y).astype('int')\n",
    "            ## will use f1 scores to see how well the modelsdo\n",
    "            clf_test_score = clf_model.score(X_test_tfidf,actualLabels)\n",
    "            ## add results to the dataframe\n",
    "            result = {\"Train Project\": df_name, \"Test Project\": df_name2, \"Prediction Score\": \"{:.2f}\".format(clf_test_score)}\n",
    "            df_scores = df_scores.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(\"PredictionScores_MultiClass.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
